---
title: "Analysis of differential gene expression from The Cancer Genome Atlas (TCGA) data set"
output: html_document
date: '2022-05-20'
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r load libary}

library(tidyverse)

getpackage <- function(pkg) 
{ 
  if(!require(pkg, character.only = TRUE)) {
    install.packages(pkg, repos="http://cran.us.r-project.org")
  }
  library(pkg, character.only = TRUE) 
}

# Vector with packages required for this script
packages <- c("tidyverse","broom","palmerpenguins","Hmisc", "ggpubr", "corrplot","GGally")
  
invisible(lapply(packages, getpackage)) 

```


#GROUPING AND FILTER DATA

```{r cars}
load('COAD_data.Rdata')


summary(samples)

cancer_data <- data.frame(samples) %>%
  filter(!is.na(Cancer_stage)) %>%
  mutate(group = case_when(
    stringr::str_detect(Cancer_stage, c('STAGE III')) ~ 'group 2',
    stringr::str_detect(Cancer_stage, c('STAGE IV')) ~ 'group 3',
    TRUE ~ 'group 1'
  ))
    
  
```

#PART 1;: Hypothesis testing for three groups 

###1. Report the total number of samples included in each group

```{r}
head(cancer_data)

table(cancer_data$group)
```
Group 1 has 260 samples
Group 2 has 127 samples
Group 3 has 62 samples

###2.	Compare age at diagnosis in the three groups
  a. The distribution of age at diagnosis for each group and report the group mean age
  
```{r}
cancer_data %>%
  filter(!is.na(Diagnosis_age)) %>%
  group_by(group) %>%
  summarise(MEAN = mean(Diagnosis_age))

bp <- cancer_data %>%
  group_by(group) %>% 
  ggplot(aes(y = Diagnosis_age, x = group, color = group)) +
  geom_boxplot() 

bp + coord_flip()
```

Here, I used boxplot to show the distribution of diagnosis age in each group.

Group 1: 
- Mean age = 69.1
- Distribution: The median line is slightly toward third
quartile with the age is about 71, which shows that more than 50% of
patients were diagnosed with cancer stage I or II older than 70. The IQR is about 18 years-old which means
about 50% of patients' ages are between 61 and 79 years-old. This group
has the length of left whisker larger as this might be the result of outliers. The distribution of this group is left skewed.

Group 2:
- Mean age = 64.5
- Distribution: The median line is a little toward third
quartile with the age is about 66, which shows that more than 50% of
patients were diagnosed with cancer stage I or II older than 66. The IQR is about 21 years-old which means
about 50% of patients' ages are between 54 and 75 years-old. The distribution of this group maybe left-skewed as we can obverse the left whisker is longer.

Group 3:
- Mean age: 63.6
- Distribution: the distribution of group 3 is similar to the group 2 with the median line is to the left, IRQ is approximately 66 and the longer left whisker. The distribution of diagnosis age might be left shewed.

  b. State the null and alternative hypotheses
$$
H_0: \sigma^2_\text{group 1} = \sigma^2_\text{group 2} = \sigma^2_\text{group 3}
$$

$$
H_a: \sigma^2_\text{group 1} \neq \sigma^2_\text{group 2} \neq \sigma^2_\text{group 3}
$$


  c. Perform the appropriate statistical test

```{r}
kruskal.test(Diagnosis_age ~ group, data = cancer_data)
```

```{r}
pairwise.wilcox.test(cancer_data$Diagnosis_age, cancer_data$group, p.adjust.method = 'BH')
```
  d. Conclusion: 

As the distribution is not normal distribution and there are more than 3 groups. I will use Kruskal-Wallis test to test if there is any significant difference between the average diagnosis age in the three groups. The p-value of this test is  roughly 0.0005, less than the significant level 0.05. Therefore, the null hypothesis is rejected and it concluded that there is different between these groups. 
In order to know which group is significantly different from the other, we compute paired samples Wilcoxon test. The pairwise comparison test indicated that group 1 is significant different from group 2 and group 3 (p < 0.05).

###3. Perform a test to determine if there is a relationship between sex and your grouping:
  a. Formulate the null and alternative hypotheses:
$$
H_0: \text{There is no relationship between sex and group}
$$
$$
H_1: \text{There is a relationship between sex and group}
$$
  b. Perform statistic test 
As sex and group are categorical variables. I will use Pearson Ï‡2 test.

```{r}
chisq.test(cancer_data$Sex, cancer_data$group)

```
  c. Conclusion:
  
X-squared value is 0.635 with p-value approximately 0.73 which is greater than the significant level 0.05. We cannot reject the null hypothesis and conclude that there is not enough evidence to suggest a relationship between sex and the grouping.

###4. Pick an additional continuous or discrete variable of your choice and perform the appropriate statistical test to compare the mean in the three groups.

  I choose Aneuploidy_score
  a. Produce a plot (of your choice) to show the distribution and the mean of each group:

```{r}
aneu_score <- cancer_data %>%
  filter(!is.na(Aneuploidy_score)) 

aneu_score %>%
  group_by(group) %>%
  summarise(MEAN = mean(Aneuploidy_score))

bp2 <- aneu_score %>%
  group_by(group) %>% 
  ggplot(aes(y = Aneuploidy_score, x = group, color = group)) +
  geom_boxplot()

bp2 + coord_flip()

```

Group 1:
- Mean: 9.8
- Distribution: the main bulk of data is over toward the low end of the scale with the longer right whisker. Therefore, the distribution of group 1 in aneuploidy score is right skewed. In addition, the median is about 9 and locate roughly in the middle of the main bulk.

Group 2:
- Mean: 12.52
- Distribution: the median line is slightly toward the first quartile with the value of around 12.5. The right whisker is likely longer, therefore, the group 2 maybe slightly right skewed.

Group 3:
- Mean: 15.36
- Distribution: the median value is approximately 16 with the line is slightly toward the right. The two whiskers seems to have the same length. Therefore, the distribution can be normal distribution as the plot is likely symmetric.

  b. Hypothesis:
  
$$
H_0: \sigma^2_\text{group 1} = \sigma^2_\text{group 2} = \sigma^2_\text{group 3}
$$

$$
H_a: \sigma^2_\text{group 1} \neq \sigma^2_\text{group 2} \neq \sigma^2_\text{group 3}
$$
  c. Statistic Test:

```{r}
kruskal.test(Aneuploidy_score ~ group, data = aneu_score)
```
```{r}
pairwise.wilcox.test(aneu_score$Aneuploidy_score, aneu_score$group, p.adjust.method = 'BH')
```
  d. Conclusion:
  
As the distribution of Aneuploidy score is not normal distribution in all three groups. I will use Kruskal-Wallis test to test if there is any significant difference between the average in the three groups. The p-value of this test is significant lower than the significant level 0.05. Therefore, the null hypothesis is rejected and it concluded that there is different between these groups. 
In order to know which group is significantly different from the other, I computed paired samples Wilcoxon test. The pairwise comparison test indicated that the pairs of group 1 - group 2, group 1 - group 3, group 2 - group 3 are significant different (p < 0.05).


#PART 2: Differential Gene Expression Analysis
```{r}
if (!requireNamespace("BiocManager", quietly = TRUE)){
      install.packages("BiocManager")
}

if (!requireNamespace("edgeR", quietly = TRUE)){
      BiocManager::install("edgeR")
}

library(edgeR)

```


###1. Generate EgdeR object
  a. DEGList
  
```{r}
raw_counts_subset <- raw_counts[,rownames(cancer_data)]

cancer_edgeR <- DGEList(counts = raw_counts_subset, samples = cancer_data, group = cancer_data$group)

head(cancer_edgeR$samples)
```

Filter the low expression:

```{r}
keep <- filterByExpr(cancer_edgeR, group = cancer_data$group)

cancer_edgeR_filt <- cancer_edgeR[keep, ,keep.lib.sizes=FALSE] 

dim(cancer_edgeR$counts)
dim(cancer_edgeR_filt$counts)
table(keep)
```
Before filtering, there were 19550 genes. After filtering, there were 16239. 3311 genes have been filtered out.

Calculate the normalization factor:
```{r}
cancer_edgeR_filt_norm <- calcNormFactors(cancer_edgeR_filt)

head(cancer_edgeR_filt_norm$samples)
```
###2. Transformation the gene expression 
  a. Transformation log2
```{r}
cancer_filt_norm_lcpm <- cancer_edgeR_filt_norm %>%
  cpm(log=TRUE, prior.count = 1)


cancer_filt_norm_lcpm[,1:50] %>%
  as.data.frame() %>%
  rownames_to_column(var="gene") %>%
  gather(key="sample", value = "logCPM(raw)",-gene) %>%
  ggplot(aes(x = `logCPM(raw)`, colour=sample)) +
  geom_density() +
  theme(legend.position = "none") +
  xlim(-10,15) 

cancer_filt_norm_lcpm[,1:50] %>%
  as.data.frame() %>%
  rownames_to_column(var="gene") %>%
  gather(key="sample", value = "logCPM(raw)",-gene) %>%
  ggplot(aes(y = `logCPM(raw)`, x=sample, color = sample)) +
  theme(legend.position = "none") +
  geom_boxplot() +
  ylim(-10,15) 

```
Most of gene in density plot close to normal distribution except for a few gene in green and blue color.
Median lines in the boxplot are at the same level.


###3. Design matrix

```{r}

# cancer_design
cancer_design <- model.matrix(~group , cancer_edgeR_filt_norm$samples)

#estimate the dispersions
cancer_edgeR_filt_norm<- estimateDisp(cancer_edgeR_filt_norm, cancer_design)

#plot the estimated dispersions
plotBCV(cancer_edgeR_filt_norm)

#build model
cancer_fit <- glmFit(cancer_edgeR_filt_norm, cancer_design)
cancer_treat <- glmTreat(cancer_fit, coef = 3, lfc = 0.5)

```

The variance is not high and had trend to go down at high level expression gene.

###4. Number of genes down- or up- regulated

```{r}
plotMD(cancer_treat)
abline(h=c(-1, 1), col="red")

topTags(cancer_treat)

summary(decideTests(cancer_treat))
```
- 51 genes are significantly down-regulated in Groups 3. 
- 131 genes are significantly up-regulated in Group 3.

###5. Top 10 differentially expressed genes sorted by p-value
```{r}
top10 <- topTags(cancer_treat, sort.by = "PValue", n = 10)
```
Top 10 genes by P-value:
```{r}
rownames(top10)
```
 
#PART 3: Principal Component Analysis 

```{r}
library(mixOmics)
```

```{r}
getpackage <- function(pkg) 
{ 
  if(!require(pkg, character.only = TRUE)) {
    install.packages(pkg, repos="http://cran.us.r-project.org")
  }
  library(pkg, character.only = TRUE) 
}

# Vector with packages required for this script
packages <- c("ggfortify")

invisible(lapply(packages, getpackage)) 
```


###1. Principal Component Analysis (PCA) on all genes 
```{r}
summary(cancer_edgeR_filt_norm$samples)
```


```{r}
#run pca code 
pca_cancer <- prcomp(t(cancer_filt_norm_lcpm), center = TRUE, scale = TRUE )

round(pca_cancer$sdev, 2)
str(pca_cancer)
```

###2.Samples plot for first two principal components
```{r}
autoplot(pca_cancer,
         data = cancer_edgeR_filt_norm$samples[rownames(pca_cancer$x),],
         colour = 'group',
         size = 5)

```

As we can see from the plot, it is hardly seen that the groups and samples are distributed into clusters.

###3. Are two components enough to explain most of the variance in the data?

```{r}
# #The square of scale as the variances of each column
pc_eigenvalues_cancer <- pca_cancer$sdev^2


# manually create a data frame with a variable indicating the PC number and a variable with the variances
pc_eigenvalues <- data_frame(PC = factor(1:length(pc_eigenvalues_cancer)), 
                         variance = pc_eigenvalues_cancer) %>% 
  # add a new column with the percent variance
  mutate(pct = variance/sum(variance)*100) %>% 
  # add another column with the cumulative variance explained
  mutate(cumulative_proportion = cumsum(pct))

# print the result
pc_eigenvalues
#plot the result
pc_eigenvalues %>% 
  ggplot(aes(x = PC)) +
  geom_col(aes(y = pct)) +
  geom_line(aes(y = cumulative_proportion, group = 1)) + 
  geom_point(aes(y = cumulative_proportion)) +
  labs(x = "Principal component", y = "Fraction variance explained")
```

From the eigenvalues table, 2 components can only cover about 29% of our variances (showing in the cumulative_proportion column).

#PART 4: Clustering and Classification 

###1.	Carry out a K-means clustering on all differentially expressed genes 
```{r}
#create data frame with differently expressed genes
dif_gene <- decideTests(cancer_treat) %>%
  as.data.frame()
dif_gene <- dif_gene %>%
  filter(dif_gene[,1] != 0)

DE_genes <- cancer_treat %>%
  as.data.frame() %>%
  filter(row.names(cancer_treat) %in% c(row.names(dif_gene))) %>%
  #convert rownames to column called "gene"
  rownames_to_column(var="gene") %>%
  # pull gene names as a vector
  pull(gene)

#get samples from group1 and 3
samples_g1_g3 <- cancer_edgeR_filt_norm$samples %>%
  filter(group != 'group 2')

#create subset with logCPM of samples from, group 1 and 3 only
trans_cancer_fnl <- t(cancer_filt_norm_lcpm)
subset_cancer_lcmp <- trans_cancer_fnl[(row.names(trans_cancer_fnl) %in% row.names(samples_g1_g3)),]
subset_cancer_lcmp <-t(subset_cancer_lcmp)

# Subset gene matrix to only include different expressed genes only
hclust_cancer <- subset_cancer_lcmp [DE_genes,]

# Scale the matrix
hclust_cancer <- hclust_cancer %>% 
  # transpose the matrix so genes are as columns
  t() %>% 
  # apply scaling to each column of the matrix (genes)
  scale() %>% 
  # transpose back so genes are as rows again
  t()

#perform Kmeans clustering
set.seed(1)

clusters_cancer <- kmeans(t(hclust_cancer), centers = 2, iter.max = 100, nstart = 25)


```
###2. Number and proportion of samples in Kmean clusters
```{r}
#add cluster group in the data frame
cancer_samp_cluster <- data.frame(samples_g1_g3,
                                  cluster = as.factor(clusters_cancer$cluster))

head(cancer_samp_cluster)
#count number of samples in each clusters
table(cancer_samp_cluster$cluster)
```
```{r}
#count number of samples in group 1 or group 3 in each cluster
cancer_samp_cluster %>%
  group_by(cluster, group) %>%
  summarise(number_of_samples = n())
```

86 samples (26.7% of total samples of group 1 and 3) were clustered together. In which, 57 belongs to group 1 and 29 belongs to group 3.

236 samples (73.3% of total samples of group 1 and 3) were clustered together in other group. In which 203 are group 1 and 33 are group 3


###3. Hierarchical clustering
```{r}
#calculate distance

hclust_cancer_sample <- subset_cancer_lcmp [DE_genes,]
hclust_cancer_sample <- hclust_cancer_sample %>% 
  # apply scaling to each column of the matrix (genes)
  scale() %>% 
  # transpose back so genes are as rows again
  t() 


#calculate distance
euc_dist_cancer <- dist(hclust_cancer_sample)
edsamp_squar_cancer <- euc_dist_cancer^2

#clustering and draw tree
eucl_clust_cancer <- hclust(edsamp_squar_cancer, method="ward.D")
plot(eucl_clust_cancer, labels=FALSE) #not include the labels as name of sample too long
eucl_gr_cancer <- cutree(eucl_clust_cancer, k = 2)
# draw dendogram with red borders around the 2 clusters
rect.hclust(eucl_clust_cancer, k = 2, border = "red")
```

###4.Number and proportion of samples in hcluster
```{r}
#count number of samples in each cluster
table(eucl_gr_cancer)
```
```{r}
#count how many sampmes in group 1 or group 3 in each cluster
table(eucl_gr_cancer, samples_g1_g3$group) 
```
76 samples (23.6%) of group1 and 3 were clustered together. In which, 73 samples are group 1 and 3 samples are group 3.

246 samples(76.4%) were clustered as the other group. In which, 187 samples are group 1 and 59 samples are group 3.

###5. Which approach better for different expressed genes

From tables above, two clustering methods divided all samples into clusters with the number of samples in each cluster is similar in both method.
However, when looking inside the number of samples of group 1 or group 3 in each cluster, the hierarchical cluster seems doing better in clustering samples of group 3 as it could cluster the majority of group 3 into one cluster with only 3 samples in other cluster. Therefore, the hierarchical clustering approach is likely better base on differently expressed gene.

# PART 5: Correlation of methylation and gene expression 
###1. Boxplot of logCPM expression of the gene of interest
```{r}
#create data frame with MLH1 logCPM
MLH1_samples <- cancer_data[, c('patient', 'sample', 'Cancer_stage', 'group')] %>%
    mutate(MLH1_logCPM = cancer_filt_norm_lcpm['MLH1|ENSG00000076242', ])

str(MLH1_samples)
#boxplot for MLH1 logCPM of each group
MLH1_samples %>%
  group_by(group) %>%
  ggplot(aes(y = MLH1_logCPM, x = group, colour = group)) +
  geom_boxplot()
```
```{r}
#check if this gene in the list of differently expressed genes
dif_gene['MLH1|ENSG00000076242', 1]
  
```
According to part 2 question 4, gene MLH1 is not in the list of differently expressed gene between group 1 and 3.

###2. Produce scatter plots along with the line of best fit showing the relationship between beta values of each methylation probe and gene expression (logCPM)

```{r}
#load methylation data
methyl_tcga <- read.csv('Methylation_TCGA.csv')
str(methyl_tcga)
#subset for gene and cancer type of interest
methyl_coad <- methyl_tcga %>%
  filter(Cancer_type == 'COAD', Gene == 'MLH1')

head(methyl_coad)
```
```{r}
#get the name of probe
probe_name  <- c(unique(methyl_coad$probe))

#loop to add beta_value of each probe in to MLH1 data frame
for (i in 1:8) {
  subset_probe <- methyl_coad %>%
              filter(probe == probe_name[i])
  
  MLH1_samples$name <- subset_probe$beta_val[match(MLH1_samples$patient,subset_probe$patient)]
  names(MLH1_samples)[names(MLH1_samples) == "name"] <- probe_name[i]
}


head(MLH1_samples)

```
```{r}
#filter the sample with NA values
MLH1_methyl <- MLH1_samples%>% 
  filter_at(vars(starts_with("cg")), any_vars(! is.na(.)))

head(MLH1_methyl)
  
```

```{r}
#plot scatter plot of MLH1 logCPM and beta value of each probe
MLH1_methyl %>% 
  tidyr::gather("id", "Beta_value", starts_with('cg')) %>% 
  ggplot(aes(Beta_value, MLH1_logCPM))+
  geom_point()+
  geom_smooth(method = "lm") +
  stat_cor(method = "pearson") +
  facet_wrap(~id)
```
###3. Pearson's correlation:
```{r}
#calculate pearson's correlation
MLH1_samples %>%
  dplyr::select(starts_with('cg'), MLH1_logCPM) %>%
  cor(use="complete.obs", method = "pearson")
```
From the calculation, the pearson's correlation values of MLH1's logCPM with the beta value of probe cg00893636, cg03192963, cg25202636, cg13846866 were large negative (pearson r aroung -0.87 or -0.88), which indicated a strong negative relationship in these pairs of variables as the methylation increases, the logCPM decreases, hence the gene expression decreases. 
In addition, from the plots in question 2, the p-value also suggested that the relationship between MLH1 expression and methylation maybe linear according to four probes mentioned above (p<0.0001). 


###4. Multiple linear regression analysis 
```{r}
#perform multiple linear model between MLH1 logCPM and probes
model_MLH1 <- lm(MLH1_logCPM ~ cg00893636 + cg03192963 + cg25202636 + cg13846866, data = MLH1_methyl)

summary(model_MLH1)
```
Intercept: 5.16771

Slope coefficients: 
  - cg00893636:  -2.72688    
  - cg03192963:  -0.15377    
  - cg25202636:   1.00659       
  - cg13846866:  -2.96236
  
Adjusted R-squares: 0.7906

Residual standard error: 0.4827

p-value: < 2.2e-16

###5. Diagnositic plot.
```{r}
#plot diagnosis plot
plot(model_MLH1)
```

Overall, in all four graphs, there are 3 outliers.

From the Residuals vs Fited plot, it can be seen that there is no distinctive pattern as the spread of residuals was quite evenly and met the regression assumptions very well. Combining the p-value (p < 0.001), the linear regression model can be fit for the observed data.

The normal Q-Q plot indicated that the majority of residuals fell into the straight line; however, there were 3 potential outliers as they were off. 

The next Scale-location plots, although the residuals seemed to spread randomly from 1 to 4 and focused near 5, the red smooth line was quite horizontal.

The last plot - Residuals vs Leverage, it showed that there was one potential influential case which was TCGA-AZ-4614-01A-01R-1410-07 as it slightly touched the Cook's distance line. I try to remove this sample and remodel:

```{r}
#filter with the potetial influence data
MLH1_methyl_filter <- MLH1_methyl %>%
  filter(row.names(MLH1_methyl) != 'TCGA-AZ-4614-01A-01R-1410-07')
#rerun multiple linear regression model
model_MLH1_filter <- lm(MLH1_logCPM ~ cg00893636 + cg03192963 + cg25202636 + cg13846866, data = MLH1_methyl_filter)

summary(model_MLH1_filter)
```
When I removed the sample, the slope coefficient of cg00893636 changed which made this probe not significant; however, adjust-R square remained unchanged. It suggested that this case needed a further inside look to know whether this was an error in data or there was any special about it which affects the result of cg00893636 result.


In order to determine whether this multiple linear model is suitable, we need to test for the multicollinearity.

```{r}
#calculate correlation between beta value of probes
probe_rcorr <- MLH1_methyl %>%
  dplyr::select(starts_with('cg')) %>%
  as.matrix() %>%
  rcorr(type="pearson")
#plot the correlation
corrplot(probe_rcorr$r, method="color",
         type="upper",
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         diag=FALSE # hide correlation coefficient on the principal diagonal
         )
```

As from the graph, the correlations between chosen probes are high (all values are near 1). This suggests that there might be a high chance for multicollinearity between these probes. Therefore, multiple linear regression model in this data is not suitable.



